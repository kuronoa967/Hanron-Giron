import streamlit as st
from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline
import torch

st.set_page_config(page_title="AIè­°è«–ãƒ‘ãƒ¼ãƒˆãƒŠãƒ¼ï¼ˆã‚ªãƒ•ãƒ©ã‚¤ãƒ³ï¼‰", layout="wide")

# -------------------------
# ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿
# -------------------------
@st.cache_resource
def load_text_model():
    model_path = "./tiny-gpt2"  # GitHub ã«åŒæ¢±ã—ãŸãƒ•ã‚©ãƒ«ãƒ€

    tokenizer = AutoTokenizer.from_pretrained(model_path)
    model = AutoModelForCausalLM.from_pretrained(model_path)

    generator = pipeline(
        "text-generation",
        model=model,
        tokenizer=tokenizer,
        max_new_tokens=120,
        temperature=0.8,
    )

    return generator


st.title("AIè­°è«–ãƒ‘ãƒ¼ãƒˆãƒŠãƒ¼ï¼ˆè»½é‡ã‚ªãƒ•ãƒ©ã‚¤ãƒ³ç‰ˆï¼‰")
st.write("OpenAI APIãªã—ãƒ»ãƒ­ãƒ¼ã‚«ãƒ«ãƒ¢ãƒ‡ãƒ«ã®ã¿ã§åè«–ãƒ»è¦ç´„ãƒ»æ”¹å–„æ¡ˆã‚’ç”Ÿæˆã—ã¾ã™ã€‚")

# ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿
with st.spinner("ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿ä¸­â€¦"):
    text_model = load_text_model()

st.success("ãƒ¢ãƒ‡ãƒ«æº–å‚™å®Œäº†ï¼")

# -------------------------
# å…¥åŠ›
# -------------------------
user_text = st.text_area("ã‚ãªãŸã®æ„è¦‹ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ï¼š", height=200)

if st.button("è­°è«–ã‚’ç”Ÿæˆ"):
    if not user_text.strip():
        st.warning("ãƒ†ã‚­ã‚¹ãƒˆã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
    else:
        with st.spinner("AIãŒè€ƒãˆã¦ã„ã¾ã™â€¦"):

            def generate(prompt):
                out = text_model(prompt)
                return out[0]["generated_text"].replace(prompt, "").strip()

            # åè«–
            prompt1 = f"æ„è¦‹: {user_text}\n\nã“ã®æ„è¦‹ã«å¯¾ã—ã¦ã€å»ºè¨­çš„ãªåè«–ã‚’è¿°ã¹ã‚ˆã€‚"
            hanron = generate(prompt1)

            # è¦ç´„
            prompt2 = f"æ–‡ç« : {user_text}\n\nã“ã®æ–‡ç« ã‚’çŸ­ãè¦ç´„ã›ã‚ˆã€‚"
            summary = generate(prompt2)

            # æ”¹å–„æ¡ˆ
            prompt3 = f"æ„è¦‹: {user_text}\n\nã“ã®æ„è¦‹ã‚’ã‚ˆã‚Šè‰¯ã„å½¢ã«æ›¸ãç›´ã›ã€‚"
            improve = generate(prompt3)

        # -------------------------
        # å‡ºåŠ›è¡¨ç¤º
        # -------------------------
        st.subheader("ğŸ“Œ AIã®åè«–")
        st.write(hanron)

        st.subheader("ğŸ“Œ è¦ç´„")
        st.write(summary)

        st.subheader("ğŸ“Œ æ”¹å–„æ¡ˆ")
        st.write(improve)
        "text-generation",
        model=model,
        tokenizer=tokenizer,
        max_new_tokens=200,
        temperature=0.7,
        do_sample=True
    )
    return gpt_pipeline

@st.cache_resource
def load_whisper_model():
    return whisper.load_model("tiny")

text_model = load_text_model()
whisper_model = load_whisper_model()

# -----------------------------
# Whisper éŸ³å£°æ–‡å­—èµ·ã“ã—
# -----------------------------
def transcribe_audio(uploaded_file: BytesIO) -> str:
    try:
        with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as tmp:
            tmp.write(uploaded_file.read())
            tmp_path = tmp.name
        result = whisper_model.transcribe(tmp_path, language="ja")
        return result.get("text", "")
    except Exception as e:
        st.error(f"éŸ³å£°ã®æ–‡å­—èµ·ã“ã—ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")
        return ""

# -----------------------------
# UIãƒ•ã‚©ãƒ¼ãƒ 
# -----------------------------
with st.form(key="debate_form"):
    input_mode = st.radio("å…¥åŠ›æ–¹æ³•ã‚’é¸æŠ", ("ãƒ†ã‚­ã‚¹ãƒˆå…¥åŠ›", "éŸ³å£°ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰"))

    user_text = ""
    uploaded_audio = None

    if input_mode == "ãƒ†ã‚­ã‚¹ãƒˆå…¥åŠ›":
        user_text = st.text_area("ã‚ãªãŸã®ä¸»å¼µã‚’å…¥åŠ›ã—ã¦ãã ã•ã„", height=120)
    else:
        uploaded_audio = st.file_uploader("éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type=["mp3", "wav", "m4a"])
        st.caption("â€» ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ã¨è‡ªå‹•ã§æ–‡å­—èµ·ã“ã—ã•ã‚Œã¾ã™")

    depth = st.selectbox("åè«–ã®æ·±ã•", ["çŸ­ã‚", "æ¨™æº–", "è©³ã—ã"])
    tone = st.selectbox("åè«–ã®ãƒˆãƒ¼ãƒ³", ["å†·é™ã§è«–ç†çš„", "å¼·ã‚ã§ç¤¼å„€æ­£ã—ã", "ã‚„ã‚ã‚‰ã‹ãèª¬å¾—çš„"])

    submitted = st.form_submit_button("AIã«è­°è«–ã—ã¦ã‚‚ã‚‰ã†")

# -----------------------------
# å®Ÿè¡Œ
# -----------------------------
if submitted:
    # éŸ³å£° â†’ ãƒ†ã‚­ã‚¹ãƒˆ
    if input_mode == "éŸ³å£°ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰" and uploaded_audio is not None:
        with st.spinner("éŸ³å£°ã‚’æ–‡å­—èµ·ã“ã—ä¸­..."):
            user_text = transcribe_audio(uploaded_audio)
            if user_text:
                st.success("æ–‡å­—èµ·ã“ã—å®Œäº†ï¼")
                st.write(f"èªè­˜: {user_text}")
            else:
                st.warning("æ–‡å­—èµ·ã“ã—ã«å¤±æ•—ã—ã¾ã—ãŸ")

    if not user_text.strip():
        st.warning("ä¸»å¼µã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
    else:
        with st.spinner("AIãŒåè«–ã‚’ç”Ÿæˆä¸­..."):
            depth_map = {
                "çŸ­ã‚": "ç°¡æ½”ã«è¦ç‚¹ã ã‘ã‚’è¿°ã¹ã¦",
                "æ¨™æº–": "è«–ç‚¹ã¨å…·ä½“ä¾‹ã‚’äº¤ãˆã¦",
                "è©³ã—ã": "è«–ç†å±•é–‹ã¨åè¨¼ä¾‹ã‚’å«ã‚ã¦"
            }
            tone_map = {
                "å†·é™ã§è«–ç†çš„": "å†·é™ã§è«–ç†çš„ã«",
                "å¼·ã‚ã§ç¤¼å„€æ­£ã—ã": "ã‚„ã‚„å¼·ã‚ã«ç¤¼å„€æ­£ã—ã",
                "ã‚„ã‚ã‚‰ã‹ãèª¬å¾—çš„": "ã‚„ã‚ã‚‰ã‹ãèª¬å¾—çš„ã«"
            }

            prompt = (
                f"ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ä¸»å¼µ:ã€Œ{user_text.strip()}ã€\n\n"
                f"{tone_map[tone]}ã€{depth_map[depth]}åå¯¾æ„è¦‹ã‚’è¿°ã¹ã€"
                f"ãã®å¾Œã«ä¸­ç«‹çš„ãªè¦ç´„ã‚’ç¤ºã—ã€"
                f"æœ€å¾Œã«ä¸»å¼µã‚’æ”¹å–„ã™ã‚‹ãŸã‚ã®3ã¤ã®æ”¹å–„æ¡ˆã‚’ææ¡ˆã—ã¦ãã ã•ã„ã€‚\n"
            )

            result = text_model(prompt)[0]["generated_text"]

        # -----------------------------
        # è¡¨ç¤º
        # -----------------------------
        st.subheader("ç”Ÿæˆçµæœ")
        st.markdown(f"""
        ### ğŸ§­ åå¯¾æ„è¦‹
        {result}

        ---

        ### âš–ï¸ ä¸­ç«‹è¦ç´„
        è­°è«–ã«ã¯è¤‡æ•°ã®è¦–ç‚¹ãŒã‚ã‚Šã€ã©ã¡ã‚‰ã«ã‚‚ä¸€å®šã®åˆç†æ€§ãŒã‚ã‚Šã¾ã™ã€‚

        ### ğŸ’¡ æ”¹å–„æ¡ˆ
        - ä¸»å¼µã‚’æ”¯ãˆã‚‹å®¢è¦³çš„ãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ ã™ã‚‹  
        - åå¯¾æ„è¦‹ã¸ã®ç†è§£ã‚’ç¤ºã—ãŸä¸Šã§ä¸»å¼µã‚’è£œå¼·ã™ã‚‹  
        - æ„Ÿæƒ…ã§ã¯ãªãè«–ç†çš„æ ¹æ‹ ã‚’ä¸­å¿ƒã«èª¬æ˜ã™ã‚‹  
        """)

        # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
        st.download_button(
            "çµæœã‚’ãƒ†ã‚­ã‚¹ãƒˆã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
            data=f"å…¥åŠ›: {user_text}\n\n{result}",
            file_name="hanron_result.txt"
        )

st.write("---")
st.caption("â€» ã“ã®ã‚¢ãƒ—ãƒªã¯å®Œå…¨ãƒ­ãƒ¼ã‚«ãƒ«ã§å‹•ä½œã—ã€APIã‚­ãƒ¼ã¯ä¸è¦ã§ã™ã€‚")
