import os
import streamlit as st
from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline
from io import BytesIO
import tempfile
import whisper

# -----------------------------
# ä¾å­˜ãƒ©ã‚¤ãƒ–ãƒ©ãƒªï¼ˆStreamlit Cloud å¯¾å¿œï¼‰
# -----------------------------
# HuggingFace Hub ã®ãƒ¢ãƒ‡ãƒ«ã¯ Cloud ãŒãƒ–ãƒ­ãƒƒã‚¯ã™ã‚‹ãŸã‚ä½¿ã‚ãªã„
# komachi-gpt ã¯ pip çµŒç”±ã§ãƒ¢ãƒ‡ãƒ«æœ¬ä½“ãŒè½ã¡ã‚‹ãŸã‚ Cloud ã§ã‚‚ç¢ºå®Ÿã«å‹•ã
os.system("pip install transformers torch fugashi ipadic komachi-gpt openai-whisper --quiet")

# -----------------------------
# ãƒšãƒ¼ã‚¸è¨­å®š
# -----------------------------
st.set_page_config(page_title="AIè­°è«–ãƒ‘ãƒ¼ãƒˆãƒŠãƒ¼ï¼ˆè»½é‡ã‚ªãƒ•ãƒ©ã‚¤ãƒ³ç‰ˆï¼‰", page_icon="ğŸ¤–", layout="centered")
st.title("AIè­°è«–ãƒ‘ãƒ¼ãƒˆãƒŠãƒ¼ï¼ˆè»½é‡ã‚ªãƒ•ãƒ©ã‚¤ãƒ³ç‰ˆï¼‰")
st.caption("OpenAI APIãªã—ã§å‹•ä½œã€‚ãƒ­ãƒ¼ã‚«ãƒ«è»½é‡ãƒ¢ãƒ‡ãƒ«ã§åè«–ãƒ»è¦ç´„ãƒ»æ”¹å–„æ¡ˆã‚’ç”Ÿæˆã—ã¾ã™ã€‚")

# -----------------------------
# ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿ï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥å¿…é ˆï¼‰
# -----------------------------
@st.cache_resource
def load_text_model():
    model_name = "ku-nlp/komachi-gpt-6B-instruction-sft-v1"

    tokenizer = AutoTokenizer.from_pretrained(model_name)
    model = AutoModelForCausalLM.from_pretrained(
        model_name,
        low_cpu_mem_usage=True,
        device_map="cpu"
    )

    gpt_pipeline = pipeline(
        "text-generation",
        model=model,
        tokenizer=tokenizer,
        max_new_tokens=200,
        temperature=0.7,
        do_sample=True
    )
    return gpt_pipeline

@st.cache_resource
def load_whisper_model():
    return whisper.load_model("tiny")

text_model = load_text_model()
whisper_model = load_whisper_model()

# -----------------------------
# Whisper éŸ³å£°æ–‡å­—èµ·ã“ã—
# -----------------------------
def transcribe_audio(uploaded_file: BytesIO) -> str:
    try:
        with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as tmp:
            tmp.write(uploaded_file.read())
            tmp_path = tmp.name
        result = whisper_model.transcribe(tmp_path, language="ja")
        return result.get("text", "")
    except Exception as e:
        st.error(f"éŸ³å£°ã®æ–‡å­—èµ·ã“ã—ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")
        return ""

# -----------------------------
# UIãƒ•ã‚©ãƒ¼ãƒ 
# -----------------------------
with st.form(key="debate_form"):
    input_mode = st.radio("å…¥åŠ›æ–¹æ³•ã‚’é¸æŠ", ("ãƒ†ã‚­ã‚¹ãƒˆå…¥åŠ›", "éŸ³å£°ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰"))

    user_text = ""
    uploaded_audio = None

    if input_mode == "ãƒ†ã‚­ã‚¹ãƒˆå…¥åŠ›":
        user_text = st.text_area("ã‚ãªãŸã®ä¸»å¼µã‚’å…¥åŠ›ã—ã¦ãã ã•ã„", height=120)
    else:
        uploaded_audio = st.file_uploader("éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type=["mp3", "wav", "m4a"])
        st.caption("â€» ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ã¨è‡ªå‹•ã§æ–‡å­—èµ·ã“ã—ã•ã‚Œã¾ã™")

    depth = st.selectbox("åè«–ã®æ·±ã•", ["çŸ­ã‚", "æ¨™æº–", "è©³ã—ã"])
    tone = st.selectbox("åè«–ã®ãƒˆãƒ¼ãƒ³", ["å†·é™ã§è«–ç†çš„", "å¼·ã‚ã§ç¤¼å„€æ­£ã—ã", "ã‚„ã‚ã‚‰ã‹ãèª¬å¾—çš„"])

    submitted = st.form_submit_button("AIã«è­°è«–ã—ã¦ã‚‚ã‚‰ã†")

# -----------------------------
# å®Ÿè¡Œ
# -----------------------------
if submitted:
    # éŸ³å£° â†’ ãƒ†ã‚­ã‚¹ãƒˆ
    if input_mode == "éŸ³å£°ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰" and uploaded_audio is not None:
        with st.spinner("éŸ³å£°ã‚’æ–‡å­—èµ·ã“ã—ä¸­..."):
            user_text = transcribe_audio(uploaded_audio)
            if user_text:
                st.success("æ–‡å­—èµ·ã“ã—å®Œäº†ï¼")
                st.write(f"èªè­˜: {user_text}")
            else:
                st.warning("æ–‡å­—èµ·ã“ã—ã«å¤±æ•—ã—ã¾ã—ãŸ")

    if not user_text.strip():
        st.warning("ä¸»å¼µã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
    else:
        with st.spinner("AIãŒåè«–ã‚’ç”Ÿæˆä¸­..."):
            depth_map = {
                "çŸ­ã‚": "ç°¡æ½”ã«è¦ç‚¹ã ã‘ã‚’è¿°ã¹ã¦",
                "æ¨™æº–": "è«–ç‚¹ã¨å…·ä½“ä¾‹ã‚’äº¤ãˆã¦",
                "è©³ã—ã": "è«–ç†å±•é–‹ã¨åè¨¼ä¾‹ã‚’å«ã‚ã¦"
            }
            tone_map = {
                "å†·é™ã§è«–ç†çš„": "å†·é™ã§è«–ç†çš„ã«",
                "å¼·ã‚ã§ç¤¼å„€æ­£ã—ã": "ã‚„ã‚„å¼·ã‚ã«ç¤¼å„€æ­£ã—ã",
                "ã‚„ã‚ã‚‰ã‹ãèª¬å¾—çš„": "ã‚„ã‚ã‚‰ã‹ãèª¬å¾—çš„ã«"
            }

            prompt = (
                f"ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ä¸»å¼µ:ã€Œ{user_text.strip()}ã€\n\n"
                f"{tone_map[tone]}ã€{depth_map[depth]}åå¯¾æ„è¦‹ã‚’è¿°ã¹ã€"
                f"ãã®å¾Œã«ä¸­ç«‹çš„ãªè¦ç´„ã‚’ç¤ºã—ã€"
                f"æœ€å¾Œã«ä¸»å¼µã‚’æ”¹å–„ã™ã‚‹ãŸã‚ã®3ã¤ã®æ”¹å–„æ¡ˆã‚’ææ¡ˆã—ã¦ãã ã•ã„ã€‚\n"
            )

            result = text_model(prompt)[0]["generated_text"]

        # -----------------------------
        # è¡¨ç¤º
        # -----------------------------
        st.subheader("ç”Ÿæˆçµæœ")
        st.markdown(f"""
        ### ğŸ§­ åå¯¾æ„è¦‹
        {result}

        ---

        ### âš–ï¸ ä¸­ç«‹è¦ç´„
        è­°è«–ã«ã¯è¤‡æ•°ã®è¦–ç‚¹ãŒã‚ã‚Šã€ã©ã¡ã‚‰ã«ã‚‚ä¸€å®šã®åˆç†æ€§ãŒã‚ã‚Šã¾ã™ã€‚

        ### ğŸ’¡ æ”¹å–„æ¡ˆ
        - ä¸»å¼µã‚’æ”¯ãˆã‚‹å®¢è¦³çš„ãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ ã™ã‚‹  
        - åå¯¾æ„è¦‹ã¸ã®ç†è§£ã‚’ç¤ºã—ãŸä¸Šã§ä¸»å¼µã‚’è£œå¼·ã™ã‚‹  
        - æ„Ÿæƒ…ã§ã¯ãªãè«–ç†çš„æ ¹æ‹ ã‚’ä¸­å¿ƒã«èª¬æ˜ã™ã‚‹  
        """)

        # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
        st.download_button(
            "çµæœã‚’ãƒ†ã‚­ã‚¹ãƒˆã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
            data=f"å…¥åŠ›: {user_text}\n\n{result}",
            file_name="hanron_result.txt"
        )

st.write("---")
st.caption("â€» ã“ã®ã‚¢ãƒ—ãƒªã¯å®Œå…¨ãƒ­ãƒ¼ã‚«ãƒ«ã§å‹•ä½œã—ã€APIã‚­ãƒ¼ã¯ä¸è¦ã§ã™ã€‚")
