import streamlit as st

from io import BytesIO

# -----------------------------
# è¨­å®š
# -----------------------------
# Streamlit ã® Secrets ã¾ãŸã¯ç’°å¢ƒå¤‰æ•°ã§ OPENAI_API_KEY ã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚
# ä¾‹: st.secrets["OPENAI_API_KEY"] ã¾ãŸã¯ç’°å¢ƒå¤‰æ•° OPENAI_API_KEY

OPENAI_KEY = st.secrets.get("OPENAI_API_KEY") if "OPENAI_API_KEY" in st.secrets else None
if not OPENAI_KEY:
    import os
    OPENAI_KEY = os.environ.get("OPENAI_API_KEY")

openai.api_key = OPENAI_KEY

# -----------------------------
# ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£é–¢æ•°
# -----------------------------

def transcribe_audio(uploaded_file: BytesIO) -> str:
    """éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ¢ãƒ‡ãƒ«ï¼ˆWhisperï¼‰ã§æ–‡å­—èµ·ã“ã—ã™ã‚‹ã€‚
    æ³¨æ„: åˆ©ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ«åã‚„ãƒ¡ã‚½ãƒƒãƒ‰ã¯å°†æ¥å¤‰ã‚ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚"""
    try:
        # openai ã® audio transcription ã‚’å‘¼ã³å‡ºã™
        # ã“ã“ã§ã¯ä¸€èˆ¬çš„ãªå‘¼ã³å‡ºã—ä¾‹ã‚’è¨˜è¼‰ã—ã¾ã™ã€‚ç’°å¢ƒã«ã‚ˆã£ã¦å¾®èª¿æ•´ã—ã¦ãã ã•ã„ã€‚
        audio_bytes = uploaded_file.read()
        audio_buffer = BytesIO(audio_bytes)
        # rewind
        audio_buffer.seek(0)
        transcript = openai.Audio.transcribe("whisper-1", audio_buffer)
        # ä¸Šã®æˆ»ã‚Šå€¤ã¯ dict ã‚„ object ã®å ´åˆãŒã‚ã‚‹ãŸã‚æŸ”è»Ÿã«
        if isinstance(transcript, dict):
            return transcript.get("text", "")
        return str(transcript)
    except Exception as e:
        st.error(f"éŸ³å£°ã®æ–‡å­—èµ·ã“ã—ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        return ""


def call_model(prompt: str, model: str = "gpt-4o-mini") -> str:
    """ãƒãƒ£ãƒƒãƒˆãƒ¢ãƒ‡ãƒ«ã‚’å‘¼ã¶ãƒ©ãƒƒãƒ‘ãƒ¼ã€‚å¿…è¦ã«å¿œã˜ã¦ system æŒ‡ç¤ºã‚„ temperature ã‚’èª¿æ•´ã—ã¦ãã ã•ã„ã€‚"""
    if not openai.api_key:
        st.error("OpenAI API key ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ç’°å¢ƒå¤‰æ•° OPENAI_API_KEY ã‹ Streamlit secrets ã«è¨­å®šã—ã¦ãã ã•ã„ã€‚")
        return ""
    try:
        response = openai.ChatCompletion.create(
            model=model,
            messages=[
                {"role": "system", "content": "ã‚ãªãŸã¯å»ºè¨­çš„ã§ç¤¼å„€æ­£ã—ã„è­°è«–ç›¸æ‰‹ã§ã™ã€‚ç›¸æ‰‹ã®æ„è¦‹ã«å¯¾ã—ã¦åå¯¾ã®ç«‹å ´ã‹ã‚‰è«–ç†çš„ãƒ»äº‹å®Ÿãƒ™ãƒ¼ã‚¹ã§åè«–ã‚’ç”Ÿæˆã—ã€æœ€å¾Œã«ä¸­ç«‹çš„ãªè¦ç´„ã¨ä¸»å¼µã‚’å¼·åŒ–ã™ã‚‹ãŸã‚ã®æ”¹å–„æ¡ˆã‚’æç¤ºã—ã¦ãã ã•ã„ã€‚"},
                {"role": "user", "content": prompt}
            ],
            temperature=0.7,
            max_tokens=800,
        )
        # OpenAI ã®æˆ»ã‚Šå€¤ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã«åˆã‚ã›ã¦æŠ½å‡º
        if isinstance(response, dict):
            choices = response.get("choices", [])
            if choices:
                return choices[0].get("message", {}).get("content", "")
        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
        return str(response)
    except Exception as e:
        st.error(f"ãƒ¢ãƒ‡ãƒ«å‘¼ã³å‡ºã—ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        return ""


# -----------------------------
# UI
# -----------------------------

st.set_page_config(page_title="AIè­°è«–ãƒ‘ãƒ¼ãƒˆãƒŠãƒ¼", page_icon="ğŸ¤–", layout="centered")
st.title("AIè­°è«–ãƒ‘ãƒ¼ãƒˆãƒŠãƒ¼")
st.caption("ã‚ãªãŸã®ä¸»å¼µã«å¯¾ã—ã¦ã€åå¯¾æ„è¦‹ãƒ»ä¸­ç«‹è¦ç´„ãƒ»æ”¹å–„æ¡ˆã‚’ç”Ÿæˆã—ã¾ã™")

with st.form(key="debate_form"):
    input_mode = st.radio("å…¥åŠ›æ–¹æ³•ã‚’é¸ã‚“ã§ãã ã•ã„", ("ãƒ†ã‚­ã‚¹ãƒˆå…¥åŠ›", "éŸ³å£°ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰"))

    user_text = ""
    uploaded_audio = None

    if input_mode == "ãƒ†ã‚­ã‚¹ãƒˆå…¥åŠ›":
        user_text = st.text_area("ã‚ãªãŸã®ä¸»å¼µã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ï¼ˆä¾‹ï¼šãƒ†ãƒ¬ãƒ¯ãƒ¼ã‚¯ã¯åŠ¹ç‡ãŒæ‚ªã„ã¨æ€ã†ï¼‰", height=120)
    else:
        uploaded_audio = st.file_uploader("éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ï¼ˆmp3, wav ç­‰ï¼‰", type=["mp3", "wav", "m4a", "ogg"])
        st.write("â€» éŸ³å£°ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ãŸã‚‰é€ä¿¡ãƒœã‚¿ãƒ³ã§æ–‡å­—èµ·ã“ã—â†’ç”Ÿæˆã‚’è¡Œã„ã¾ã™")

    depth = st.selectbox("åè«–ã®æ·±ã•ï¼ˆç›®å®‰ï¼‰", ["çŸ­ã‚ï¼ˆè¦ç‚¹ã®ã¿ï¼‰", "æ¨™æº–ï¼ˆè«–ç‚¹ï¼‹å…·ä½“ä¾‹ï¼‰", "è©³ã—ãï¼ˆè«–ç†å±•é–‹ï¼‹åè¨¼ä¾‹ï¼‰"]) 
    tone = st.selectbox("åè«–ã®ãƒˆãƒ¼ãƒ³", ["å†·é™ã§è«–ç†çš„", "å¼·ã‚ã§åè«–çš„ã ã‘ã©ç¤¼å„€æ­£ã—ã„", "ã‚„ã‚ã‚‰ã‹ãèª¬å¾—çš„"]) 

    submitted = st.form_submit_button("AIã«è­°è«–ã—ã¦ã‚‚ã‚‰ã†")

if submitted:
    # å…¥åŠ›ãƒã‚§ãƒƒã‚¯
    if input_mode == "ãƒ†ã‚­ã‚¹ãƒˆå…¥åŠ›" and not user_text.strip():
        st.warning("ã¾ãšã¯ã‚ãªãŸã®ä¸»å¼µã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
    else:
        # éŸ³å£°ãŒã‚ã‚‹å ´åˆã¯æ–‡å­—èµ·ã“ã—
        if input_mode == "éŸ³å£°ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰":
            if not uploaded_audio:
                st.warning("éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
            else:
                with st.spinner("éŸ³å£°ã‚’æ–‡å­—èµ·ã“ã—ã—ã¦ã„ã¾ã™..."):
                    user_text = transcribe_audio(uploaded_audio)
                    if user_text:
                        st.success("æ–‡å­—èµ·ã“ã—ãŒå®Œäº†ã—ã¾ã—ãŸã€‚ä»¥ä¸‹ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’å…ƒã«è­°è«–ã‚’ç”Ÿæˆã—ã¾ã™ã€‚")
                        st.write(user_text)
                    else:
                        st.error("æ–‡å­—èµ·ã“ã—ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
        # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä½œæˆ
        if user_text and user_text.strip():
            # depth ã¨ tone ã‚’ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«åæ˜ 
            depth_map = {
                "çŸ­ã‚ï¼ˆè¦ç‚¹ã®ã¿ï¼‰": "short",
                "æ¨™æº–ï¼ˆè«–ç‚¹ï¼‹å…·ä½“ä¾‹ï¼‰": "standard",
                "è©³ã—ãï¼ˆè«–ç†å±•é–‹ï¼‹åè¨¼ä¾‹ï¼‰": "detailed",
            }
            tone_map = {
                "å†·é™ã§è«–ç†çš„": "calm and logical",
                "å¼·ã‚ã§åè«–çš„ã ã‘ã©ç¤¼å„€æ­£ã—ã„": "firm but polite",
                "ã‚„ã‚ã‚‰ã‹ãèª¬å¾—çš„": "gentle and persuasive",
            }

            prompt = (
                f"ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ä¸»å¼µ: \"{user_text.strip()}\"\n"
                f"ã‚¿ã‚¹ã‚¯: ä»¥ä¸‹ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚\n"
                f"1) ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ä¸»å¼µã«å¯¾ã™ã‚‹åå¯¾æ„è¦‹ï¼ˆç«‹å ´ã‚’å–ã£ã¦è«–ç†çš„ã«å±•é–‹ã™ã‚‹ï¼‰ã€‚ãƒˆãƒ¼ãƒ³: {tone_map[tone]}ã€‚è©³ç´°ãƒ¬ãƒ™ãƒ«: {depth_map[depth]}ã€‚\n"
                f"2) åå¯¾æ„è¦‹ã®çŸ­ã„ä¸­ç«‹çš„ãªè¦ç´„ï¼ˆ2ã€œ3æ–‡ï¼‰\n"
                f"3) æœ€å¾Œã«ã€Œã‚ãªãŸã®ä¸»å¼µã‚’ã‚ˆã‚Šå¼·ãã™ã‚‹ãŸã‚ã®æ”¹å–„æ¡ˆã€ã‚’3ã¤ã€å®Ÿè¡Œå¯èƒ½ãªç®‡æ¡æ›¸ãã§æŒ™ã’ã‚‹ã€‚\n"
                f"å‡ºåŠ›å½¢å¼: è¦‹å‡ºã—ä»˜ãï¼ˆ\"åå¯¾æ„è¦‹:\", \"ä¸­ç«‹è¦ç´„:\", \"æ”¹å–„æ¡ˆ:\"ï¼‰ã§ã‚ã‹ã‚Šã‚„ã™ãã€‚"
            )

            with st.spinner("AIãŒè­°è«–ã‚’ç”Ÿæˆã—ã¦ã„ã¾ã™..."):
                result = call_model(prompt)

            if result:
                # è¡¨ç¤º
                st.subheader("ç”Ÿæˆçµæœ")
                st.markdown(result)

                # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ç”¨ãƒ†ã‚­ã‚¹ãƒˆ
                download_text = f"---\nå…¥åŠ›: {user_text.strip()}\n---\n\n{result}"
                st.download_button("çµæœã‚’ãƒ†ã‚­ã‚¹ãƒˆã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", data=download_text, file_name="ai_debate_result.txt")
        else:
            st.warning("å‡¦ç†ã™ã‚‹ãƒ†ã‚­ã‚¹ãƒˆãŒã‚ã‚Šã¾ã›ã‚“ã€‚")

# ãƒ•ãƒƒã‚¿ãƒ¼
st.write("---")
st.write("ãƒ’ãƒ³ãƒˆ: ãƒˆãƒ¼ãƒ³ã‚„æ·±ã•ã‚’å¤‰ãˆã‚‹ã“ã¨ã§ã€ã•ã¾ã–ã¾ãªåè«–ã®è§’åº¦ã‚’è©¦ã›ã¾ã™ã€‚OpenAI APIã‚­ãƒ¼ã¯ç’°å¢ƒå¤‰æ•°OPENAI_API_KEY ã¾ãŸã¯ Streamlit secrets ã«ã‚»ãƒƒãƒˆã—ã¦ãã ã•ã„ã€‚")
